{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.3\n"
     ]
    }
   ],
   "source": [
    "# check opencv version\n",
    "import cv2\n",
    "# print version number\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the photograph\n",
    "pixels = cv2.imread('test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173  74 108 108]\n",
      "[363 104  97  97]\n"
     ]
    }
   ],
   "source": [
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407 160  28  28]\n",
      "[ 97 268  49  49]\n",
      "[208 264  46  46]\n",
      "[316 270  44  44]\n",
      "[366 156  43  43]\n",
      "[153 148  42  42]\n",
      "[ 64 152  36  36]\n",
      "[253 145  46  46]\n",
      "[504 155  41  41]\n",
      "[258  18  65  65]\n",
      "[451 262  40  40]\n",
      "[335  29  35  35]\n",
      "[315 249  50  50]\n",
      "[128  30  40  40]\n",
      "[219  40  42  42]\n",
      "[427  48  38  38]\n"
     ]
    }
   ],
   "source": [
    "# example of face detection with opencv cascade classifier\n",
    "from cv2 import imread\n",
    "from cv2 import CascadeClassifier\n",
    "# load the photograph\n",
    "pixels = imread('test2.jpg')\n",
    "# load the pre-trained model\n",
    "classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230],\n",
       "        [232, 230, 230]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[112, 123, 145],\n",
       "        [124, 135, 157],\n",
       "        [133, 141, 164],\n",
       "        ...,\n",
       "        [ 97, 169, 241],\n",
       "        [ 98, 167, 240],\n",
       "        [ 96, 168, 240]],\n",
       "\n",
       "       [[146, 158, 186],\n",
       "        [151, 163, 191],\n",
       "        [148, 160, 188],\n",
       "        ...,\n",
       "        [ 99, 170, 238],\n",
       "        [ 99, 168, 238],\n",
       "        [ 98, 168, 238]],\n",
       "\n",
       "       [[143, 153, 183],\n",
       "        [145, 155, 185],\n",
       "        [139, 149, 179],\n",
       "        ...,\n",
       "        [ 99, 169, 236],\n",
       "        [101, 168, 237],\n",
       "        [ 99, 168, 237]]], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract\n",
    "x, y, width, height = box\n",
    "x2, y2 = x + width, y + height\n",
    "# draw a rectangle over the pixels\n",
    "cv2.rectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "cv2.imshow('face detection', pixels)\n",
    "# keep the window open until we press a key\n",
    "cv2.waitKey(0)\n",
    "# close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photo with detected faces using opencv cascade classifier\n",
    "from cv2 import imread\n",
    "from cv2 import imshow\n",
    "from cv2 import waitKey\n",
    "from cv2 import destroyAllWindows\n",
    "from cv2 import CascadeClassifier\n",
    "from cv2 import rectangle\n",
    "# load the photograph\n",
    "cv2els = cv2.imread('test2.jpg')\n",
    "# load the pre-trained model\n",
    "classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "    # extract\n",
    "    x, y, width, height = box\n",
    "    x2, y2 = x + width, y + height\n",
    "    # draw a rectangle over the pixels\n",
    "    rectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)\n",
    "# show the image\n",
    "cv2.imshow('face detection', pixels)\n",
    "# keep the window open until we press a key\n",
    "cv2.waitKey(0)\n",
    "# close the window\n",
    "destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the photograph\n",
    "pixels = cv2.imread(r\"C:\\Users\\Admin\\Project\\FaceDetectionDeeplearning\\italy.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels, 1.1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels, 1.05, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
